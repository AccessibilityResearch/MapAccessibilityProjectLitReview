#Aaron Cherney .bib file
@article{doi:10.1080/10447318.2017.1279827,
author = {Radu-Daniel Vatavu},
title = {Visual Impairments and Mobile Touchscreen Interaction: State-of-the-Art, Causes of Visual Impairment, and Design Guidelines},
journal = {International Journal of Human–Computer Interaction},
volume = {33},
number = {6},
pages = {486-509},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/10447318.2017.1279827},

URL = { 
        https://doi.org/10.1080/10447318.2017.1279827
    
},
eprint = { 
        https://doi.org/10.1080/10447318.2017.1279827
    
}

}

@inproceedings{10.1145/2468356.2468364,
author = {Abd Hamid, Nazatul Naquiah and Edwards, Alistair D.N.},
title = {Facilitating Route Learning Using Interactive Audio-Tactile Maps for Blind and Visually Impaired People},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468364},
doi = {10.1145/2468356.2468364},
abstract = {In preparing to navigate in an unfamiliar location, a blind person may use non-visual maps. This project is aimed at developing more effective, interactive audio-tactile maps. The maps will be novel in using speech and non-speech sounds and allowing the user to rotate the map, thereby facilitating the building of an egocentric cognitive map. Initial requirements have been gathered from mobility instructors. Their main conclusions are that immoveable objects represent the most useful landmarks and that certain ambient sounds can provide most valuable orientation information.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {37–42},
numpages = {6},
keywords = {orientation, touch, audio-tactile maps, route learning, blindness, visual impairment, speech, auditory icons, multimodal, accessibility, tactile maps},
location = {Paris, France},
series = {CHI EA '13}
}

@article{10.1145/2815169.2815171,
author = {Medina, Jonathas Leontino and Cagnin, Maria Istela and Paiva, D\'{e}bora Maria Barroso},
title = {Investigating Accessibility on Web-Based Maps},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1559-6915},
url = {https://doi.org/10.1145/2815169.2815171},
doi = {10.1145/2815169.2815171},
abstract = {This paper presents results of an accessibility evaluation carried out with web-based map applications. Three points of view were considered: experts on accessibility, evaluation tools and final users (partially or totally blind people). The document WCAG 2.0 (Web Content Accessibility Guidelines) provided us with guidelines for evaluation and GQM (Goal, Question and Metric) approach was used to define and set measurable goals. A number of problems was identified and none of the evaluated applications entirely meet the analyzed criteria.},
journal = {SIGAPP Appl. Comput. Rev.},
month = {aug},
pages = {17–26},
numpages = {10},
keywords = {web-based maps, accessibility evaluation, web accessibility, WCAG 2.0}
}

@InProceedings{10.1007/978-3-319-41267-2_20,
author="G{\"o}tzelmann, Timo",
editor="Miesenberger, Klaus
and B{\"u}hler, Christian
and Penaz, Petr",
title="CapMaps",
booktitle="Computers Helping People with Special Needs",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="146--152",
abstract="Tactile maps can be useful tools for blind people for navigation and orientation tasks. Apart from static maps, there are techniques to augment tactile maps with audio content. They can be used to interact with the map content, to offer extra information and to reduce the tactile complexity of a map. Studies show that audio-tactile maps can be more efficient and satisfying for the user than pure tactile maps without audio feedback. A major challenge of audio-tactile maps is the linkage of tactile elements with audio content and interactivity. This paper introduces a novel approach to link 3D printed tactile maps with mobile devices, such as smartphones and tablets, in a flexible way to enable interactivity and audio-support. By integrating conductive filaments into the printed maps it seamlessly integrates into the 3D printing process. This allows to automatically recognize the tactile map by a single press at its corner. Additionally, the arrangement of the tactile map on the mobile device is flexible and detected automatically which eases the use of these maps. The practicability of this approach is shown by a dedicated feasibility study.",
isbn="978-3-319-41267-2"
}

@article{RODRIGUEZSANCHEZ20147210,
title = {Accessible smartphones for blind users: A case study for a wayfinding system},
journal = {Expert Systems with Applications},
volume = {41},
number = {16},
pages = {7210-7222},
year = {2014},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2014.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S095741741400311X},
author = {M.C. Rodriguez-Sanchez and M.A. Moreno-Alvarez and E. Martin and S. Borromeo and J.A. Hernandez-Tamames},
keywords = {Accessibility, Visually impaired users, User interfaces, Touch screens, Wayfinding},
abstract = {While progress on assistive technologies have been made, some blind users still face several problems opening and using basic functionalities when interacting with touch interfaces. Sometimes, people with visual impairments may also have problems navigating autonomously, without personal assistance, especially in unknown environments. This paper presents a complete solution to manage the basic functions of a smartphone and to guide users using a wayfinding application. This way, a blind user could go to work from his home in an autonomous way using an adaptable wayfinding application on his smartphone. The wayfinding application combines text, map, auditory and tactile feedback for providing the information. Eighteen visually impaired users tested the application. Preliminary results from this study show that blind people and limited vision users can effectively use the wayfinding application without help. The evaluation also confirms the usefulness of extending the vibration feedback to convey distance information as well as directional information. The validation was successful for iOS and Android devices.}
}

@InProceedings{10.1007/978-3-319-07440-5_15,
author="Neto, Jos{\'e} Monserrat
and Freire, Andr{\'e} P.
and Souto, Sabrina S.
and Ab{\'i}lio, Ramon S.",
editor="Stephanidis, Constantine
and Antona, Margherita",
title="Usability Evaluation of a Web System for Spatially Oriented Audio Descriptions of Images Addressed to Visually Impaired People",
booktitle="Universal Access in Human-Computer Interaction. Universal Access to Information and Knowledge",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="154--165",
abstract="This paper describes a web system designed to provide spatially oriented audio descriptions of an image for visually impaired users. The system uses a hardware-independent platform of the technique of multimodal presentation of images. Visually impaired users interact with an image displayed on the screen while moving the cursor -- with a mouse or a tablet (pen or finger touch) -- and listening to the audio description of previously marked areas within the image. The paper also describes the usability evaluation performed with five participants and its main results. Generally, the five participants accomplished the usability test tasks and could better understand the image displayed. The paper also describes the main findings and discusses some implications for design, suggesting some improvements.",
isbn="978-3-319-07440-5"
}

@article{LAHIB201816,
title = {Evaluating Fitts’ law on vibrating touch-screen to improve visual data accessibility for blind users},
journal = {International Journal of Human-Computer Studies},
volume = {112},
pages = {16-27},
year = {2018},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2018.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1071581918300053},
author = {Manahel El Lahib and Joe Tekli and Youssef Bou Issa},
keywords = {Blind users, Pointing method, Visual data accessibility, Fitts’ law, Vibrating touch-screen},
abstract = {The pointing task is the process of pointing to an object on a computer monitor using a pointing device, or physically touching an object with the hand or finger. It is an important element for users when manipulating visual computer interfaces such as traditional screens and touch-screens. In this context, Fitts’ Law remains one of the central studies that have mathematically modeled the pointing method, and was found to be a good predictor of the average time needed to perform a pointing task. Yet, in our modern computerized society, accessing visual information becomes a central need for all kinds of users, namely users who are blind or visually impaired. Hence, the goal of our study is to evaluate whether Fitts’ Law can be applied for blind candidates using the vibration modality on a touch-screen. To achieve this, we first review the literature on Fitts’ Law and visual data accessibility solutions for blind users. Then, we introduce an experimental framework titled FittsEVAL studying the ability of blind users to tap specific shapes on a touch-screen, while varying different parameters, namely: target distance, target size, and the angle of attack of the pointing task. Experiments on blindfolded and blind candidates show that Fitts’ Law can be effectively applied for blind users using a vibrating touch-screen under certain parameters (i.e., when varying target distance and size), while it is not verified under others (i.e., when varying the angle of attack). This can be considered as a first step toward a more complete experimental evaluation of vibrating touch-screen accessibility, toward designing more adapted interfaces for the blind.}
}

@inproceedings{10.1145/3373625.3416999,
author = {Sharif, Ather and Pao, Victoria and Reinecke, Katharina and Wobbrock, Jacob O.},
title = {The Reliability of Fitts’s Law as a Movement Model for People with and without Limited Fine Motor Function},
year = {2020},
isbn = {9781450371032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373625.3416999},
doi = {10.1145/3373625.3416999},
abstract = {For over six decades, Fitts’s law (1954) has been utilized by researchers to quantify human pointing performance in terms of “throughput,” a combined speed-accuracy measure of aimed movement efficiency. Throughput measurements are commonly used to evaluate pointing techniques and devices, helping to inform software and hardware developments. Although Fitts’s law has been used extensively in HCI and beyond, its test-retest reliability, both in terms of throughput and model fit, from one session to the next, is still unexplored. Additionally, despite the fact that prior work has shown that Fitts’s law provides good model fits, with Pearson correlation coefficients commonly at r=.90 or above, the model fitness of Fitts’s law has not been thoroughly investigated for people who exhibit limited fine motor function in their dominant hand. To fill these gaps, we conducted a study with 21 participants with limited fine motor function and 34 participants without such limitations. Each participant performed a classic reciprocal pointing task comprising vertical ribbons in a 1-D layout in two sessions, which were at least four hours and at most 48 hours apart. Our findings indicate that the throughput values between the two sessions were statistically significantly different, both for people with and without limited fine motor function, suggesting that Fitts’s law provides low test-retest reliability. Importantly, the test-retest reliability of Fitts’s throughput metric was 4.7% lower for people with limited fine motor function. Additionally, we found that the model fitness of Fitts’s law as measured by Pearson correlation coefficient, r, was .89 (SD=0.08) for people without limited fine motor function, and .81 (SD=0.09) for people with limited fine motor function. Taken together, these results indicate that Fitts’s law should be used with caution and, if possible, over multiple sessions, especially when used in assistive technology evaluations.},
booktitle = {The 22nd International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {16},
numpages = {15},
keywords = {throughput, models, Fitts’s law, model fitness, test-retest reliability, mouse},
location = {Virtual Event, Greece},
series = {ASSETS '20}
}