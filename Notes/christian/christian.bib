@inproceedings{10.1145/2207676.2207734,
author = {Yatani, Koji and Banovic, Nikola and Truong, Khai},
title = {SpaceSense: Representing Geographical Information to Visually Impaired People Using Spatial Tactile Feedback},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207734},
doi = {10.1145/2207676.2207734},
abstract = {Learning an environment can be challenging for people with visual impairments. Braille maps allow their users to understand the spatial relationship between a set of places. However, physical Braille maps are often costly, may not always cover an area of interest with sufficient detail, and might not present up-to-date information. We built a handheld system for representing geographical information called SpaceSense, which includes custom spatial tactile feedback hardware-multiple vibration motors attached to different locations on a mobile touch-screen device. It offers high-level information about the distance and direction towards a destination and bookmarked places through vibrotactile feedback to help the user maintain the spatial relationships between these points. SpaceSense also adapts a summarization technique for online user reviews of public and commercial venues. Our user study shows that participants could build and maintain the spatial relationships between places on a map more accurately with SpaceSense compared to a system without spatial tactile feedback. They pointed specifically to having spatial tactile feedback as the contributing factor in successfully building and maintaining their mental map.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {415–424},
numpages = {10},
keywords = {handheld devices, geographical information representation, users with visual impairments, touch screens, vibrotactile feedback, assistive technology},
location = {Austin, Texas, USA},
series = {CHI '12}
}
@inproceedings{10.1145/1851600.1851606,
author = {Su, Jing and Rosenzweig, Alyssa and Goel, Ashvin and de Lara, Eyal and Truong, Khai N.},
title = {Timbremap: Enabling the Visually-Impaired to Use Maps on Touch-Enabled Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851606},
doi = {10.1145/1851600.1851606},
abstract = {Mapping applications on mobile devices have gained widespread popularity as a means for enhancing user mobility and ability to explore new locations and venues. Visually impaired users currently rely on computer text-to-speech or human-spoken descriptions of maps and indoor spaces. Unfortunately, speech-based descriptions are limited in their ability to succinctly convey complex layouts or spacial positioning.This paper presents Timbremap, a sonification interface enabling visually impaired users to explore complex indoor layouts using off-the-shelf touch-screen mobile devices. This is achieved using audio feedback to guide the user's finger on the device's touch interface to convey geometry. Our user-study evaluation shows Timbremap is effective in conveying non-trivial geometry and enabling visually impaired users to explore indoor layouts.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {17–26},
numpages = {10},
keywords = {sonification, assistive, touch device, user interface},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}
@article{10.1145/3186894, author = {G\"{o}tzelmann, T.}, title = {Visually Augmented Audio-Tactile Graphics for Visually Impaired People}, year = {2018}, issue_date = {June 2018}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {11}, number = {2}, issn = {1936-7228}, url = {https://doi.org/10.1145/3186894}, doi = {10.1145/3186894}, abstract = {Tactile graphics play an essential role in knowledge transfer for blind people. The tactile exploration of these graphics is often challenging because of the cognitive load caused by physiological constraints and their complexity. The coupling of physical tactile graphics with electronic devices offers to support the tactile exploration by auditory feedback. Often, these systems have strict constraints regarding their mobility or the process of coupling both components. Additionally, visually impaired people cannot appropriately benefit from their residual vision. This article presents a concept for 3D printed tactile graphics, which offers to use audio-tactile graphics with usual smartphones or tablet-computers. By using capacitive markers, the coupling of the tactile graphics with the mobile device is simplified. These tactile graphics integrating these markers can be printed in one turn by off-the-shelf 3D printers without any post-processing and allows us to use multiple elevation levels for graphical elements. Based on the developed generic concept on visually augmented audio-tactile graphics, we presented a case study for maps. A prototypical implementation was tested by a user study with visually impaired people. All the participants were able to interact with the 3D printed tactile maps using a standard tablet computer. To study the effect of visual augmentation of graphical elements, we conducted another comprehensive user study. We tested multiple types of graphics and obtained evidence that visual augmentation may offer clear advantages for the exploration of tactile graphics. Even participants with a minor residual vision could solve the tasks with visual augmentation more quickly and accurately.}, journal = {ACM Trans. Access. Comput.}, month = {jun}, articleno = {8}, numpages = {31}, keywords = {visually impaired, blind, global, marker, touch screen, capacitive, orientation, Tactile graphics, audio-tactile, accessibility, capacitive sensing, augmented, 3D printing, tangible user interfaces}
}
@article{COBO2017294,
title = {Differences between blind people's cognitive maps after proximity and distant exploration of virtual environments},
journal = {Computers in Human Behavior},
volume = {77},
pages = {294-308},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217305332},
author = {Antonio Cobo and Nancy E. Guerrón and Carlos Martín and Francisco {del Pozo} and José Javier Serrano},
keywords = {Cognitive mapping, Blind people, Virtual reality, Smartphone},
abstract = {Visits to simulations of real spaces in virtual reality have been proposed as a means for blind people to gain spatial knowledge regarding the disposition of obstacles within a place before actually visiting it. Within the present study, different configurations of distant and proximity exploration were compared to each other, in order to test whether differences in effectiveness and efficiency lead to changes in exploration behaviour, without a detrimental impact on cognitive-map quality and usefulness. Evidence supports effectiveness improvements due to distant exploration (p-value = 0.0006). The flat-spotlight distant-configuration entails a 53% reduction in discovery time (p-value = 0.0027). A trend is observed entailing a 38% reduction in the duration of the overall exploration stage for a flat spotlight configuration (p-value = 0.067). Wall-detection effectiveness alters exploration duration (p-value = 0.012). Improvements in effectiveness and discovery time are associated with shorter overall exploration time. Duration of exploration after discovery time depends on wall-detection effectiveness. Benefits from a distant exploration configuration are not enough to build better cognitive maps.}
}
@Article{electronics10080953,
AUTHOR = {Oh, Uran and Joh, Hwayeon and Lee, YunJung},
TITLE = {Image Accessibility for Screen Reader Users: A Systematic Review and a Road Map},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {953},
URL = {https://www.mdpi.com/2079-9292/10/8/953},
ISSN = {2079-9292},
ABSTRACT = {A number of studies have been conducted to improve the accessibility of images using touchscreen devices for screen reader users. In this study, we conducted a systematic review of 33 papers to get a holistic understanding of existing approaches and to suggest a research road map given identified gaps. As a result, we identified types of images, visual information, input device and feedback modalities that were studied for improving image accessibility using touchscreen devices. Findings also revealed that there is little study how the generation of image-related information can be automated. Moreover, we confirmed that the involvement of screen reader users is mostly limited to evaluations, while input from target users during the design process is particularly important for the development of assistive technologies. Then we introduce two of our recent studies on the accessibility of artwork and comics, AccessArt and AccessComics, respectively. Based on the identified key challenges, we suggest a research agenda for improving image accessibility for screen reader users.},
DOI = {10.3390/electronics10080953}
}
@inproceedings{10.1145/3173574.3173772,
author = {Holloway, Leona and Marriott, Kim and Butler, Matthew},
title = {Accessible Maps for the Blind: Comparing 3D Printed Models with Tactile Graphics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173772},
doi = {10.1145/3173574.3173772},
abstract = {Tactile maps are widely used in Orientation and Mobility (O&amp;M) training for people with blindness and severe vision impairment. Commodity 3D printers now offer an alternative way to present accessible graphics, however it is unclear if 3D models offer advantages over tactile equivalents for 2D graphics such as maps. In a controlled study with 16 touch readers, we found that 3D models were preferred, enabled the use of more easily understood icons, facilitated better short term recall and allowed relative height of map elements to be more easily understood. Analysis of hand movements revealed the use of novel strategies for systematic scanning of the 3D model and gaining an overview of the map. Finally, we explored how 3D printed maps can be augmented with interactive audio labels, replacing less practical braille labels. Our findings suggest that 3D printed maps do indeed offer advantages for O&amp;M training.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {vision impairment, orientation and mobility training, mapping, blindness, 3d printing, accessibility},
location = {Montreal QC, Canada},
series = {CHI '18}
}