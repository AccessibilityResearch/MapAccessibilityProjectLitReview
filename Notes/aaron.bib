



@article{doi:10.1080/10447318.2017.1279827,
author = {Radu-Daniel Vatavu},
title = {Visual Impairments and Mobile Touchscreen Interaction: State-of-the-Art, Causes of Visual Impairment, and Design Guidelines},
journal = {International Journal of Human–Computer Interaction},
volume = {33},
number = {6},
pages = {486-509},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/10447318.2017.1279827},

URL = { 
        https://doi.org/10.1080/10447318.2017.1279827
    
},
eprint = { 
        https://doi.org/10.1080/10447318.2017.1279827
    
}

}




@inproceedings{10.1145/2468356.2468364,
author = {Abd Hamid, Nazatul Naquiah and Edwards, Alistair D.N.},
title = {Facilitating Route Learning Using Interactive Audio-Tactile Maps for Blind and Visually Impaired People},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468364},
doi = {10.1145/2468356.2468364},
abstract = {In preparing to navigate in an unfamiliar location, a blind person may use non-visual maps. This project is aimed at developing more effective, interactive audio-tactile maps. The maps will be novel in using speech and non-speech sounds and allowing the user to rotate the map, thereby facilitating the building of an egocentric cognitive map. Initial requirements have been gathered from mobility instructors. Their main conclusions are that immoveable objects represent the most useful landmarks and that certain ambient sounds can provide most valuable orientation information.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {37–42},
numpages = {6},
keywords = {orientation, touch, audio-tactile maps, route learning, blindness, visual impairment, speech, auditory icons, multimodal, accessibility, tactile maps},
location = {Paris, France},
series = {CHI EA '13}
}