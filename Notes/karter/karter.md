---
title: "Karter's Research Review"
output: pdf_document
bibliography: karter.bib
---

# Table of Contents

[TOC]

\newpage

# Evaluation of Virtual Tactile Dots on Touchscreens in Map Reading: Perception of Distance and Direction

## Citation

[@watanabe2017evaluation]

## Introduction

In order to assist blind people in using a flat touchscreen, "virtual" tactile dots that produce feedback either as speech and vibration or both when touched was proposed. This was then tested with a map application to investigate their effectiveness in map reading application.

Two experiments involving eight blind participants where the participants would perceive the distance and direction between two virtual tactile dots was conducted.

The paper cites the issue that while several navigation maps exist for blind people that can be used with a screen reader, their functions are limited to providing local, point information such as the address of the present location, searching for shops around the present or designated location, and navigating at intersections.

The paper then says that these apps do not provide enough geographical information, including the whole route. It then recommends that for blind people to obtain this area information, two-dimensional tactile maps are necessary.

It's stated that for map apps to display dynamic map information, tactile maps made with thermoform, capsule paper and embossed paper are insufficient and refreshable tactile displays are necessary. The paper cites that development of refreshable tactile display technology, and the issue that refreshable tactile displays are too big and heavy to carry, and too expensive to purchase personally.

As a result based from cited sources, few people use tactile display products. Mainstream touchscreen devices which are smaller, easier to carry and more reasonably priced than specially developed equipment for people with disabilities can have their speech output and vibrating functions be utilized as a substitute of tactile information.

The paper cites that researchers have proposed the use of vibrotactile and speech feedback for blind people using a flat touchscreen. The function of vibrotactile feedback is to vibrate when the predesignated areas are touched on the screen and what is on that place is voiced simultaneously, and this is what this paper refers to as "virtual tactile dots".

The paper cites topics in the introductory such as tactile perception of distance, direction, and length in the field of education for the blind, man-machine interfacing, and tactile perception for robots and in virtual reality.

Against this background, the paper explores if vibrotactile and audio feedback can give the accurate perception of distance and direction that is required in map reading. Their accuracy and time performance was compared with those for â€œrealâ€ tactile dots made on capsule paper. On the basis of these experimental results, the paper discusses the effectiveness of the vibrating and reading map app in assisting blind users.

## Study

> -   Experiment 1: Distance Perception
> -   Experiment 2: Direction Perception

## Conclusion

The results of the study showed that while the participants perception of the direction and distance between two virtual tactile dots was, by quote, "-accurate enough". The problem encountered was that the search time for these virtual tactile dots was significantly longer than the search for real dots.

The study concludes that the search time issue makes the reading and vibrating tactile map not practical. The reason for this is stated that even though 7 out of 8 participants consistently used smartphones everyday, the issue arises that unlike the app layout of their phones which can be easily remembered, the virtual tactile dots have not been told or memorized by participants.

The study declares that if it takes more than 10 or 20 seconds, the speech and vibrating map can not be said to be useful.

And so the paper attempts to suggest a method of shortening the search time, but the barriers to reducing the search time are that the device can convey the "presence" of vibration but not its "location". More vibrating motors could help facilitate this search. The flat touchscreen is also devoid of tactile information by itself, and the paper states that without tactile dots the search time can not be shortened enough to be practical.

It is stated that an innovative, small, refreshable tactile display device that realize such dots must be developed.

## Lessons Learned

> -   Modern smartphones do not contain enough vibrating motors, correctly placed, to effectively facilitate location finding of virtual tactile dots.
> -   Refreshable tractile displays are useful for understanding dynamic map information; but are commonly unobtainable due to size, weight, and price.
> -   While navigation by vibrotactile feedback is possible and can be accurate, the time to do so can be too long. As such, the overarching concern is practicability.

## Questions

1.) What ways can we overcome the limitations of the limited amount of motors in smartphones?
2.) How can we reduce the amount of time required for information retrieval by the visually impaired?
3.) Reducing the search time would make the vibrotactile map feasible, how can Fittz's law apply?

\newpage

# Evolution of the Information-Retrieval System for Blind and Visually-Impaired People

## Citation

[@dobrivsek2003evolution]

## Introduction

Slovenian paper published July 2003

In the mid-nineties the paper's research group decided to develop an information retrieval system suitable for Slovene-speaking blind and visually-impaired people. A voice-driven text-to-speech dialogue system was developed for reading Slovenian texts obtained from the Electronic Information System of the Association of Slovenian Blind and Visually Impaired Persons Societies. The evolution of the system is presented.

## Conclusion

The development of the paper's voice driven text to speech dialogue system is expected to evolve towards a specialized web browser with a mouse driven text to speech screen reader and voice driven dialogue management and that improvements in the sense of more accurate and robust speech recognition and a user friendly system to control high quality speech synthesis.

## Lessons Learned

This paper is not inherently relevant to any methods of decreasing the amount of time it takes for blind or visually impaired people to retrieve information, and is more so about being able to facilitate the act of being able to retrieve information in the first place than performance increase.

\newpage

# Examination of the Level of Inclusion of Blind Subjects in the Development of Touchscreen Accessibility Technologies

## Citation

[@thompson2018examination]

## Introduction

2018 paper, fairly recent. This is one of the papers that cited Aaron's paper,(Evaluating Fitts’ law on vibrating touch-screen to improve visual data accessibility for blind users).

This is mostly a surface level dissertation that explores the efforts of designing accesibility technology for the blind, and the consequences of not including blind participation, or even blind research, in the development of said technologies. It also includes interesting discussion of a lack of standards across applications and hardware and the results of such disparity.

> -   there are two core reasons as to
>     why this paper states this dissertation exists. The first is to identify a key gap within the body of research that deals with improving touchscreen accessibility for the blind.

> -   The second reason is to collect a body of data on both blindness and touchscreen accessibility for blindness in order to make it easier to avoid these types of shortcomings in the future.

## Study

There is no study beyond a collection of research and suggestions for future research/applications.

## Conclusion

Initially, this paper was to be an exploration of the current research and existing accessibility tools available to the blind in order to allow them to utilize touchscreen devices, particularly with regards to mobile internet. However, it was discovered in the course of the initial survey of literature that some of the research, especially pieces concerning the development of new hardware, frequently lacked references to research on blindness, and in some cases blind participants. So the subject changed and instead became an exploration of the impact of these decisions on the validity of the research results

## Lessons Learned

> -   The inclusion of Blind/visually impaired participants is very important to ensuring that what is being developed is useful to the group it's being devloped for.
> -   The development of software/hardware should have referenced research to support its development.

## Questions

\newpage

# Feasibility of Using Haptic Directions through Maps with a Tablet and Smart Watch for People who are Blind and Visually Impaired

## Citation

[@10.1145/2935334.2935367]

## Introduction

Published September 2016.

This paper includes a study that includes two prototypes intended to test users' ability to trace graphical lines and directions through Maps on a touch screen using Haptic feedback from an Android smartwatch and tablet.

The research contributes a prototype with two devices that are easily available, a smartwatch and tablet to determine distance between vibrating lines. A comparative user study with this prototype at

## Study

## Conclusion

The first prototype showed that blind and visually impaired users had a lower threshold than sighted users for determining the distance between two lines on a touchscreen. The plaper suggested that the blind and visually impaired users had an enhanced ability to form representations lot spacial distance from tactile vibrational cues.

The paper's second prototype explores this by showing that it is feasible for blind and visually impaired users to follow directions through graphical maps haggard on vibrational cues.

The paper states that it believes the results from the prototypes show that they have the potential to be effective in real-world applications.

## Lessons Learned

## Questions

\newpage

# The Sound and Feel of Titrations: A Smartphone Aid for Color-Blind and Visually Impaired Students

[@bandyopadhyay2017sound]

## Introduction

This paper discusses an Android based application that has been developed to provide colorblind and visually impaired students a multi-sensory perception of color change observed in a titration.

(Titration is a technique where a solution of known concentration is used to determine the concentration of an unknown solution; color change often occurs.)

The application that was developed records and converts color information into beep sounds and vibration pulses which are generated by the smartphone.

The application uses a combination of hue, saturation, and value for detecting a color change specific to an indicator, e.g., shades of pink; and informs the user before and upon attending the endpoint.

This approach can enable color blind and visually impaired students to actively perform a fairly routine laboratory activity of titration.

## Study

> -   There does not seem to be any user testing included in the document, it appears that the app was released on the Play store and visually impaired users were able to try it anonymously. There is no formal user study included.

> -   A summarized process scheme involved in the detection of color change includes the following steps:

1. The user chooses to point the camera near the area on the conical flask where the titrant is added dropwise to the titrand solution. The area viewed through a crosshair is stored by the camera function of the application when the device is pointed at the area of concern in the “record” mode.

2. The data stored in the stored pixel is converted to RGB (red, green, blue) values.

3. RGB data is then converted to the corresponding hex code value and HSV. The hex code is used to return the name of the detected color by cross-referencing with the color-name database. (24)

4. For a particular indicator, e.g. phenolphthalein, a hue coordinate (from HSV color space) range is specified. This range encompasses all the colors that can appear while performing titration using any of the commonly used indicators as given as an option in the app. Additionally, a saturation value (from HSV color space) threshold ensures that the app detects and responds to the color change above a certain background noise.

5. When the application signals a color change, the hue and saturation values of the detected color satisfy the conditions mentioned above. For notification of the change, the device generates beeps and vibration pulses. This auditory and tactile feedback assists a student to comprehend that a color change has occurred.

## Conclusion

The titration app “Titration ColorCam” is available on the Google Play store for Android enter devices. The paper cites without evidence that between users that are not visually impaired and users that are basically impaired, using the app to complete titrations has similar user error.

The paper cites that the application allows visually impaired to autonomously complete titrations with minimal assistance from fellow students, and concludes on a hopeful note that the application could be further developed into a mobile friendly app that allows students to effectively complete titration experiments despite being visually impaired.

## Lessons Learned

> -   mobile phones offer a low cost means of software accessibility for the visually impaired

> -   Vibration and audio feedback can be useful for relaying information to the visually impaired.

## Questions

If we were to pursue navigation or information, would a mobile app be effective for economic accessibility?

This mobile application doesn't allow an individual to know what colors are hy sound or vibration alone, only to indicate when changes are taking place. What studies do have this? Is it feasible?

\newpage
